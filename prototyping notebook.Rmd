---
title: "R Notebook"
output:
  html_document:
    df_print: paged
---
# Spectral variance across the western United States

## Setup Python environment
  I'm using the environment provided by the Earth Data Science class. https://www.earthdatascience.org/workshops/setup-earth-analytics-python/
  
  I'm running python from Rstudio. This chunk tells rstudio how to find that environment.
```{r}
library(reticulate)
#library(usethis)

#use_python("/Users/ty/opt/miniconda3/bin/python")
#use_virtualenv("~/myenv")
#use_condaenv(condaenv = "r-nlp", conda = "/Users/ty/opt/miniconda3/envs/earth-analytics-python/opt/miniconda3")
#use_virtualenv("/Users/ty/opt/miniconda3/envs/earth-analytics-python/bin/python3")
py_config()
#edit_r_environ()
```
Load python packages
```{python}
import pandas as pd
import geopandas
import matplotlib.pyplot as plt
import numpy as np
import plotnine
import contextily as cx
import requests
import json
```


## Filter metadata to decide what you're going to try to download.
A small csv version of the neon metadate exists on the NEON website. Download this file and load it into python.
https://www.neonscience.org/resources/learning-hub/tutorials/neon-api-01-introduction-requests


```{python}
metadata = pd.read_csv('data/NEON_Field_Site_Metadata_20220224.csv')
print(metadata.field_site_id)
```

## R code to translate into python code
```{r}
library(tidyverse)
library(sf)
library(maps)
```

Steps:
1) Read in the metadata csv
2) Spatially project those metadata so we can do spatial filters
3) Calculate a bounding box around the available NEON sites
4) Download a basemap and make sure it has the same spatial projection as your data.
```{r}
metadata_read = read.csv('data/NEON_Field_Site_Metadata_20220224.csv')

metatdata <- st_as_sf(metadata_read, coords = c("field_longitude", "field_latitude"), crs=4326)

bb <- st_bbox(metatdata)

usa <- st_as_sf(map_data("usa"), coords = c( "long", "lat"), crs=4326)

```

Plot the NEON sites
```{r}
ggplot() +
  geom_sf(data = usa, col="white") +
  geom_sf(data=metatdata,aes( color=field_avg_number_of_green_days), size=5) +
  coord_sf(xlim = c(bb[1], bb[3]), ylim = c(bb[2], bb[4]))
```

Filter your data to only include terrestrial sites
```{r}
terrestrial_sites <- metatdata %>% 
  filter(field_site_type == "Core Terrestrial" | field_site_type == "Gradient Terrestrial" ) 

as.data.frame(terrestrial_sites)
```

Plot your filtered data.
```{r}
ggplot() +
  geom_sf(data = usa, col="white") +
  geom_sf(data=terrestrial_sites,aes( color=field_avg_number_of_green_days), size=5) +
  coord_sf(xlim = c(bb[1], bb[3]), ylim = c(bb[2], bb[4]))
```

Filter your data with a bounding box to only include sites in the "west"
```{r}
box <- c(xmin = -130, ymin = 25, xmax = -100, ymax = 50)
west_us_terrestrial_neon_sites <- metatdata %>% 
  filter(field_site_type == "Core Terrestrial" | field_site_type == "Gradient Terrestrial" ) %>%
  st_crop(box)

as.data.frame(west_us_terrestrial_neon_sites)
```
Plot your western points to confirm that you have properly filtered them.
```{r}
ggplot() +
  geom_sf(data = usa, col="white") +
  geom_sf(data=west_us_terrestrial_neon_sites,aes( color=field_avg_number_of_green_days), size=2) +
  coord_sf(xlim = c(box[1], box[3]), ylim = c(box[2], box[4]))
```

Filter the western NEON sites to only include sites with Evergreen trees present. 
```{r}
west_us_terrestrial_Evergreen_neon_sites <- metatdata %>% 
  filter(field_site_type == "Core Terrestrial" | field_site_type == "Gradient Terrestrial" ) %>%
  filter(field_dominant_nlcd_classes !=  "Grassland/Herbaceous" & field_dominant_nlcd_classes !=  "Shrub/Scrub" & field_dominant_nlcd_classes != "Cultivated Crops") %>%
  st_crop(box)

as.data.frame(west_us_terrestrial_Evergreen_neon_sites)
```

Plot your Evergreen filter to confirm that your filter worked properly. 
```{r}
ggplot() +
  geom_sf(data = usa, col="white") +
  geom_sf(data=west_us_terrestrial_Evergreen_neon_sites,aes( color=field_mean_canopy_height_m), size=2) +
  coord_sf(xlim = c(box[1], box[3]), ylim = c(box[2], box[4]))
```

## Learn how to use an API
Select one of the sitecodes from your filtered metadataset above and enter it below. Follow the tutorial offered by NEON to explore the data structure and organizational scheme for neon api data. 

https://www.neonscience.org/resources/learning-hub/tutorials/neon-api-01-introduction-requests

```{python}
SERVER = 'http://data.neonscience.org/api/v0/'
SITECODE = 'NIWO'

site_request = requests.get(SERVER+'sites/'+SITECODE)

#Convert to Python JSON object
site_json = site_request.json()
site_json.keys()

site_json['data'].keys()

site_json
```



```{python}
site_json['data'].keys()
```


```{python}
for product in site_json['data']['dataProducts']:
    print(product['dataProductCode'],product['dataProductTitle'])
    
```



```{python}

PRODUCTCODE = 'DP2.30011.001'
```


```{python}
#Get available months of Breeding Landbird Count data products for TEAK site
#Loop through the 'dataProducts' list items (each one a dict) at the site
for product in site_json['data']['dataProducts']: 
    if(product['dataProductCode'] == PRODUCTCODE): #If a list item's 'dataProductCode' dict element equals the product code string,
        print('Available Months: ',product['availableMonths']) #print the available months and URLs
        print('URLs for each Month: ', product['availableDataUrls'])
```


```{python}
#Make Request
data_request = requests.get(SERVER+'data/'+PRODUCTCODE+'/'+SITECODE+'/'+'2020-08')
data_json = data_request.json()

print(data_json)
```


```{r}
py$data_json
```



